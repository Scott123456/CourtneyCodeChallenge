{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP3X5Qe5Qw8eJYMsDLk+hX6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Python-PySpark Coding Challenge\n","Purpose: Load purchases and products, combine, and summarize for reporting.\n","\n","Written by: Scott Davis 2023-03-27"],"metadata":{"id":"domgc3O8uhXf"}},{"cell_type":"code","source":["import pandas as pd"],"metadata":{"id":"V1ejUnFRMH53","executionInfo":{"status":"ok","timestamp":1679965683220,"user_tz":360,"elapsed":109,"user":{"displayName":"Scott Davis","userId":"14786070551703896335"}}},"execution_count":138,"outputs":[]},{"cell_type":"code","source":["import pyspark\n","from pyspark.sql import SparkSession\n","spark = SparkSession.builder.getOrCreate()"],"metadata":{"id":"Uh7e1an4Najt","executionInfo":{"status":"ok","timestamp":1679965683476,"user_tz":360,"elapsed":7,"user":{"displayName":"Scott Davis","userId":"14786070551703896335"}}},"execution_count":139,"outputs":[]},{"cell_type":"code","source":["# show raw CSV files in filesystem - optional\n","!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SQ9qBX50NnZt","executionInfo":{"status":"ok","timestamp":1679965683686,"user_tz":360,"elapsed":216,"user":{"displayName":"Scott Davis","userId":"14786070551703896335"}},"outputId":"a415ecee-a005-4209-9b72-faff252c7eb1"},"execution_count":140,"outputs":[{"output_type":"stream","name":"stdout","text":["CustomerPurchasesDataset.csv  ProductDetailsDataset.csv  sample_data\n"]}]},{"cell_type":"code","source":["# Import raw data to see structure - optional\n","\n","#dfCust = spark.read.csv(\"CustomerPurchasesDataset.csv\", header = True, quote = \"\\'\")\n","#dfProd = spark.read.csv(\"ProductDetailsDataset.csv\", header = True, quote = \"\\'\")\n","\n","#dfCust.show()\n","#dfCust.printSchema()\n","\n","#dfProd.show()\n","#dfProd.printSchema()"],"metadata":{"id":"Imm7byLKZi1h","executionInfo":{"status":"ok","timestamp":1679965683687,"user_tz":360,"elapsed":7,"user":{"displayName":"Scott Davis","userId":"14786070551703896335"}}},"execution_count":141,"outputs":[]},{"cell_type":"code","source":["from pyspark.sql.types import StructType, StructField, StringType, DoubleType, IntegerType"],"metadata":{"id":"tIgTYQRhSn7p","executionInfo":{"status":"ok","timestamp":1679965683687,"user_tz":360,"elapsed":6,"user":{"displayName":"Scott Davis","userId":"14786070551703896335"}}},"execution_count":142,"outputs":[]},{"cell_type":"code","source":["# Assign data types\n","schemaCust = StructType([\n","    StructField('customer_id', IntegerType()),\n","    StructField('product_id', IntegerType()),\n","    StructField('purchase_amount', DoubleType())\n","])\n","\n","schemaProd = StructType([\n","    StructField('product_id', IntegerType()),\n","    StructField('product_name', StringType()),\n","    StructField('unit_price', DoubleType())\n","])\n"],"metadata":{"id":"XAu-2fPjVdMN","executionInfo":{"status":"ok","timestamp":1679965683688,"user_tz":360,"elapsed":7,"user":{"displayName":"Scott Davis","userId":"14786070551703896335"}}},"execution_count":143,"outputs":[]},{"cell_type":"code","source":["# read raw data with schema definitions\n","dfCust = spark.read.csv(\"CustomerPurchasesDataset.csv\", header = True, quote = \"\\'\", schema = schemaCust)\n","dfProd = spark.read.csv(\"ProductDetailsDataset.csv\", header = True, quote = \"\\'\", schema = schemaProd)"],"metadata":{"id":"XjKTBIncY0mK","executionInfo":{"status":"ok","timestamp":1679965683688,"user_tz":360,"elapsed":7,"user":{"displayName":"Scott Davis","userId":"14786070551703896335"}}},"execution_count":144,"outputs":[]},{"cell_type":"code","source":["# show data\n","dfCust.show()\n","dfCust.printSchema()\n","\n","dfProd.show()\n","dfProd.printSchema()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M4-AmQSMSPW5","executionInfo":{"status":"ok","timestamp":1679965683844,"user_tz":360,"elapsed":162,"user":{"displayName":"Scott Davis","userId":"14786070551703896335"}},"outputId":"b8e370a3-2727-419e-9d2e-322a3ce2116a"},"execution_count":145,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----------+----------+---------------+\n","|customer_id|product_id|purchase_amount|\n","+-----------+----------+---------------+\n","|        101|      1001|           50.0|\n","|        101|      1002|           75.0|\n","|        102|      1001|          100.0|\n","|        103|      1003|           25.0|\n","|        104|      1004|          150.0|\n","+-----------+----------+---------------+\n","\n","root\n"," |-- customer_id: integer (nullable = true)\n"," |-- product_id: integer (nullable = true)\n"," |-- purchase_amount: double (nullable = true)\n","\n","+----------+------------+----------+\n","|product_id|product_name|unit_price|\n","+----------+------------+----------+\n","|      1001|   Product A|      10.0|\n","|      1002|   Product B|      15.0|\n","|      1003|   Product C|       5.0|\n","|      1004|   Product D|      20.0|\n","|      1005|   Product E|      30.0|\n","+----------+------------+----------+\n","\n","root\n"," |-- product_id: integer (nullable = true)\n"," |-- product_name: string (nullable = true)\n"," |-- unit_price: double (nullable = true)\n","\n"]}]},{"cell_type":"markdown","source":["## Problem 1\n","A PySpark DataFrame containing the joined data with the following columns:\n"," -\tcustomer_id\n"," - \tproduct_id\n"," -\tpurchase_amount\n"," -\tproduct_name\n"," -\tunit_price"],"metadata":{"id":"cnwxulKojmJ6"}},{"cell_type":"code","source":["# inner join on product_id and drop excess join column\n","dfJoin1 = dfCust.join(dfProd, dfCust.product_id == dfProd.product_id, how = 'inner').drop(dfProd.product_id)\n","dfJoin1.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2P0Y80jIZTeh","executionInfo":{"status":"ok","timestamp":1679965684783,"user_tz":360,"elapsed":943,"user":{"displayName":"Scott Davis","userId":"14786070551703896335"}},"outputId":"097cb8a2-18ec-4053-e796-75f0f38e25ae"},"execution_count":146,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----------+----------+---------------+------------+----------+\n","|customer_id|product_id|purchase_amount|product_name|unit_price|\n","+-----------+----------+---------------+------------+----------+\n","|        102|      1001|          100.0|   Product A|      10.0|\n","|        101|      1001|           50.0|   Product A|      10.0|\n","|        101|      1002|           75.0|   Product B|      15.0|\n","|        103|      1003|           25.0|   Product C|       5.0|\n","|        104|      1004|          150.0|   Product D|      20.0|\n","+-----------+----------+---------------+------------+----------+\n","\n"]}]},{"cell_type":"markdown","source":["## Problem 2\n","\n","A PySpark DataFrame containing the total revenue generated by each product with the following columns:\n"," - product_id\n"," - product_name\n"," - total_revenue"],"metadata":{"id":"bmKC1tS3kFdI"}},{"cell_type":"code","source":["# use joined data, group by product, sum by purchase amount, and rename sum column\n","dfJoin2 = dfJoin1.groupBy('product_id', 'product_name').sum('purchase_amount').orderBy('product_id').withColumnRenamed('sum(purchase_amount)', 'total_revenue')\n","dfJoin2.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_Qub4kcljMcx","executionInfo":{"status":"ok","timestamp":1679965685014,"user_tz":360,"elapsed":238,"user":{"displayName":"Scott Davis","userId":"14786070551703896335"}},"outputId":"a5f98da5-6123-4c27-840a-57677669647d"},"execution_count":147,"outputs":[{"output_type":"stream","name":"stdout","text":["+----------+------------+-------------+\n","|product_id|product_name|total_revenue|\n","+----------+------------+-------------+\n","|      1001|   Product A|        150.0|\n","|      1002|   Product B|         75.0|\n","|      1003|   Product C|         25.0|\n","|      1004|   Product D|        150.0|\n","+----------+------------+-------------+\n","\n"]}]},{"cell_type":"markdown","source":["# Problem 3\n","A PySpark DataFrame containing the total revenue generated by each customer with the following columns:\n"," - customer_id\n"," - total_revenue\n"],"metadata":{"id":"m2WH6n3Vq7Bz"}},{"cell_type":"code","source":["# use joined data, group by customer, sum purchase amount, and rename sum column\n","dfJoin3 = dfJoin1.groupBy('customer_id').sum('purchase_amount').orderBy('customer_id').withColumnRenamed('sum(purchase_amount)', 'total_revenue')\n","dfJoin3.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j4188lpBnWZk","executionInfo":{"status":"ok","timestamp":1679965685547,"user_tz":360,"elapsed":538,"user":{"displayName":"Scott Davis","userId":"14786070551703896335"}},"outputId":"34df5377-9ba4-4434-e2c7-ee1e40936f24"},"execution_count":148,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----------+-------------+\n","|customer_id|total_revenue|\n","+-----------+-------------+\n","|        101|        125.0|\n","|        102|        100.0|\n","|        103|         25.0|\n","|        104|        150.0|\n","+-----------+-------------+\n","\n"]}]},{"cell_type":"markdown","source":["## Problem 4\n","A PySpark DataFrame containing the top 5 products by revenue with the following columns:\n"," - product_id\n"," - product_name\n"," - total_revenue\n"],"metadata":{"id":"Z5H5vMp7rToC"}},{"cell_type":"code","source":["# use output from product summary above, sort descending by purchase amount, keep top 5\n","dfJoin4 = dfJoin2.orderBy('total_revenue', ascending = False).limit(5)\n","dfJoin4.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PUl8X0ahrOX6","executionInfo":{"status":"ok","timestamp":1679965686024,"user_tz":360,"elapsed":481,"user":{"displayName":"Scott Davis","userId":"14786070551703896335"}},"outputId":"30521093-bffc-4ace-d23a-2895f2a990cb"},"execution_count":149,"outputs":[{"output_type":"stream","name":"stdout","text":["+----------+------------+-------------+\n","|product_id|product_name|total_revenue|\n","+----------+------------+-------------+\n","|      1001|   Product A|        150.0|\n","|      1004|   Product D|        150.0|\n","|      1002|   Product B|         75.0|\n","|      1003|   Product C|         25.0|\n","+----------+------------+-------------+\n","\n"]}]},{"cell_type":"markdown","source":["## Problem 5\n","A PySpark DataFrame containing the top 5 customers by revenue with the following columns:\n"," - customer_id\n"," - total_revenue\n"],"metadata":{"id":"Me7_xpjFt556"}},{"cell_type":"code","source":["# use output from customer summary above, sort descending by purchase amount, keep top 5\n","dfJoin5 = dfJoin3.orderBy('total_revenue', ascending = False).limit(5)\n","dfJoin5.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QpyA_xMOr7zY","executionInfo":{"status":"ok","timestamp":1679965686927,"user_tz":360,"elapsed":906,"user":{"displayName":"Scott Davis","userId":"14786070551703896335"}},"outputId":"b0123ea5-ddf4-467c-d193-bf1762ae2d22"},"execution_count":150,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----------+-------------+\n","|customer_id|total_revenue|\n","+-----------+-------------+\n","|        104|        150.0|\n","|        101|        125.0|\n","|        102|        100.0|\n","|        103|         25.0|\n","+-----------+-------------+\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"5Zi-JzTnuFm-","executionInfo":{"status":"ok","timestamp":1679965686928,"user_tz":360,"elapsed":7,"user":{"displayName":"Scott Davis","userId":"14786070551703896335"}}},"execution_count":150,"outputs":[]}]}